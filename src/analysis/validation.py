from __future__ import annotations

import json
import os
from typing import Dict, List, Optional

import pandas as pd

from . import utils
from .analysis import prepare_series
from .config import load_config
from .logutil import get_logger
from .model_registry import REGISTRY

# Ensure wrappers are imported so decorators register models
from .models import wrappers as _model_wrappers  # noqa: F401


def _load_processed_files(processed_dir: str) -> List[str]:
    files = []
    for f in os.listdir(processed_dir):
        if f.lower().endswith((".csv", ".xlsx")):
            files.append(os.path.join(processed_dir, f))
    return files


def _load_and_prepare(path: str, logger) -> Optional[pd.Series]:
    try:
        df = utils.load_dataset(path)
        df = utils.clean_df(df)
        series, time_col, target_col = prepare_series(df, logger)
        return series
    except Exception:
        logger.exception("Prep failed for %s", path)
        return None


def run_validation(models: Optional[List[str]] = None, max_files: Optional[int] = None) -> Dict:
    cfg = load_config()
    logger = get_logger("crystalball.validation")
    processed = cfg.paths.processed_dir
    files = _load_processed_files(processed)
    if max_files:
        files = files[: max_files]

    registry = REGISTRY.available(models)
    results: Dict[str, Dict] = {}

    for model_name, entry in registry.items():
        results[model_name] = {"ok": 0, "fail": 0, "errors": [], "runs": []}

    for path in files:
        series = _load_and_prepare(path, logger)
        if series is None or len(series) < 6:
            continue
        test_size = max(1, int(len(series) * cfg.settings.test_size_fraction))
        for model_name, entry in registry.items():
            try:
                out = entry["runner"](series, test_size=test_size, exog=None)
                ok = isinstance(out, dict) and out.get("error") is None
                results[model_name]["ok" if ok else "fail"] += 1
                if not ok:
                    results[model_name]["errors"].append({"file": os.path.basename(path), "error": out.get("error")})
                results[model_name]["runs"].append({
                    "file": os.path.basename(path),
                    "mae": out.get("mae"),
                    "rmse": out.get("rmse"),
                })
            except Exception as e:
                logger.exception("Model %s failed on %s", model_name, path)
                results[model_name]["fail"] += 1
                results[model_name]["errors"].append({"file": os.path.basename(path), "error": str(e)})

    # write report
    out_dir = os.path.join(processed, "validation")
    os.makedirs(out_dir, exist_ok=True)
    report_path = os.path.join(out_dir, "validation_report.json")
    with open(report_path, "w", encoding="utf-8") as fh:
        json.dump(results, fh, indent=2, default=str)

    return {"report": report_path, "summary": {k: {"ok": v["ok"], "fail": v["fail"]} for k, v in results.items()}}


def write_model_readmes() -> List[str]:
    from .model_registry import _DECORATOR_REGISTRY as DEC
    cfg = load_config()
    out_dir = os.path.join(cfg.paths.processed_dir, "model_docs")
    os.makedirs(out_dir, exist_ok=True)
    paths: List[str] = []
    for name, info in DEC.items():
        md = [
            f"# {name}\n",
            "\n",
            f"Tags: {', '.join(info.tags)}\n",
            "\n",
            "## Inputs\n",
            "- series: pandas.Series (datetime index or monotonic integer)\n",
            "- test_size: int (holdout length)\n",
            "- exog: optional pandas.DataFrame with aligned exogenous regressors\n",
            "\n",
            "## Outputs\n",
            "A dict with keys such as: forecast (Series or array), fitted, mae, rmse, error (optional).\n",
            "\n",
            "## Notes\n",
            "This file is auto-generated by the validation harness and meant as a quick reference.\n",
        ]
        p = os.path.join(out_dir, f"{name}.md")
        with open(p, "w", encoding="utf-8") as fh:
            fh.writelines(md)
        paths.append(p)
    return paths
